{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6bfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not renaming the file manually to push my skills\n",
    "# Parallel process iamges to reduce time taken\n",
    "# save and delete due to space constraints\n",
    "# Realization accuracy is a bad measure ( dummy )\n",
    "# Defining custom metric macro F1 for imbalanced data\n",
    "# Class weights and SMOTE and ADAM to deal with imbalance\n",
    "# Why SMOTE only for training data\n",
    "# Changed RElu to ELU\n",
    "# Changed Macro F1 class from tf to numpy since im using only CPU\n",
    "# Changed ADAM to NADAM\n",
    "# Changed Macro F1 class back to tf since im dealing with tensors (lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39d2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dont run beyond 60 lack of computation - 92% ram \n",
    "## try 40 next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438f8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pathlib\n",
    "import PIL\n",
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "lower_age_limit = 1\n",
    "upper_age_limit = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5fdd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_files = ['part1.tar.gz', 'part2.tar.gz', 'part3.tar.gz']\n",
    "output_folder = os.path.join(os.getcwd(), 'all_images')\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "    for tar_file in tar_files:\n",
    "        with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "            for member in tar.getmembers():\n",
    "                # Remove the leading directory name from the member's name\n",
    "                member.name = os.path.basename(member.name)\n",
    "                tar.extract(member, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd1c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('.//all_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac124e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24106\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('**/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea221a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_images_dict = {}\n",
    "ages_labels_dict = {}\n",
    "bin_size = 1\n",
    "\n",
    "for i in range(lower_age_limit, upper_age_limit, bin_size):\n",
    "    age_bin = []\n",
    "    for j in range(bin_size):\n",
    "        age_bin.extend(list(data_dir.glob(f'{i+j}_*')))\n",
    "        age_images_dict[i] = age_bin\n",
    "        ages_labels_dict[i] = (i - lower_age_limit) // bin_size\n",
    "    \n",
    "    #age_images_dict[i] = list(data_dir.glob(f'{i}_*'))\n",
    "    #ages_labels_dict[i] = i-1\n",
    "\n",
    "# some ages are missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa5a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def process_image(image):\n",
    "    try:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,(180,180))\n",
    "        return resized_img\n",
    "    except cv2.error as e:\n",
    "        print(f\"Error processing {image}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for age_number, images in age_images_dict.items():\n",
    "        for image in images:\n",
    "            future = executor.submit(process_image, image)\n",
    "            futures.append((future, age_number))\n",
    "\n",
    "    for future, age_number in futures:\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            x.append(result)\n",
    "            y.append(ages_labels_dict[age_number])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88585fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez( os.getcwd() + '/ age_image_data.npz', x, y)\n",
    "del x, y, age_images_dict, ages_labels_dict, futures, result, images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aeebeb",
   "metadata": {},
   "source": [
    "# # run from here if saved .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78eeef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2abee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(y_true, y_pred):\n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.int32)\n",
    "\n",
    "    # Calculate the number of true positive, false positive, and false negative predictions for each class\n",
    "    true_positives = tf.cast(tf.math.count_nonzero(y_true * y_pred, axis=0), tf.float32)\n",
    "    false_positives = tf.cast(tf.math.count_nonzero((1 - y_true) * y_pred, axis=0), tf.float32)\n",
    "    false_negatives = tf.cast(tf.math.count_nonzero(y_true * (1 - y_pred), axis=0), tf.float32)\n",
    "\n",
    "    # Calculate precision and recall for each class\n",
    "    precision = true_positives / (true_positives + false_positives + 1e-6)\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-6)\n",
    "\n",
    "    # Calculate the F1 score for each class\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "\n",
    "    # Calculate the macro-averaged F1 score by taking the mean of the F1 scores for each class\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba62c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.getcwd() + '/ age_image_data.npz', mmap_mode='c') as data:\n",
    "    x = data['arr_0']\n",
    "    y = data['arr_1']\n",
    "\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85b488c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81e76def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28]\n",
      "Counts: [ 969  406  237  211  142  104  110  197  132  126   56  106   62  116\n",
      "  128  188  106  191   79  219  270  311  323  630  564 1623  455  696\n",
      "  434]\n"
     ]
    }
   ],
   "source": [
    "#sm = SMOTE(random_state=0)\n",
    "sm = RandomUnderSampler(random_state=0)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "X_train_smote = X_train_smote.reshape(X_train_smote.shape[0], X_train.shape[1], X_train.shape[2], 3)\n",
    "\n",
    "unique_elements, counts = np.unique(y_train, return_counts=True)\n",
    "print(f'Unique elements: {unique_elements}')\n",
    "print(f'Counts: {counts}')\n",
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45a40410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28]\n",
      "Counts: [56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56\n",
      " 56 56 56 56 56]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts = np.unique(y_train_smote, return_counts=True)\n",
    "print(f'Unique elements: {unique_elements}')\n",
    "print(f'Counts: {counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b384500",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Rescaling(scale = 1./255, offset=0.0),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(180, 180, 3)),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        layers.experimental.preprocessing.RandomZoom(0.1)    \n",
    "    ]\n",
    ")\n",
    " \n",
    "model = Sequential([\n",
    "    \n",
    "    data_augmentation,\n",
    "    \n",
    "    layers.Conv2D(64, 3, padding='valid', activation='elu', input_shape = (180,180,3)), # padding='same'\n",
    "    layers.MaxPooling2D(), \n",
    "    \n",
    "    layers.Conv2D(128, 3, padding='valid', activation='elu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Conv2D(256, 3, padding='valid', activation='elu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='elu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(256, activation='elu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy', metrics=[macro_f1])\n",
    "es = EarlyStopping(monitor='macro_f1', verbose=0, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e082dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "51/51 [==============================] - 92s 2s/step - loss: 3.7157 - macro_f1: 0.4852\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 93s 2s/step - loss: 3.4389 - macro_f1: 0.4703\n",
      "51/51 [==============================] - 18s 350ms/step - loss: 3.2095 - macro_f1: 0.4709\n",
      "0.4709165692329407\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_smote, y_train_smote, epochs=20, callbacks=[es])\n",
    "print(model.evaluate(X_train_smote,y_train_smote)[1])\n",
    "del X_train_smote, y_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b60d2a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 34s 350ms/step - loss: 3.4363 - macro_f1: 0.4564\n",
      "0.45641443133354187\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 180, 180, 3)\n",
    "print(model.evaluate(X_test,y_test)[1])\n",
    "del X_test,y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
